{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WEEK2_lab.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 출처:http://allendowney.github.io/ThinkBayes2/chap04.html"
      ],
      "metadata": {
        "id": "8LyXo5qcXYmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever you survey people about sensitive issues, you have to deal with social desirability bias, which is the tendency of people to adjust their answers to show themselves in the most positive light. One way to improve the accuracy of the results is randomized response.\n",
        "\n",
        "As an example, suppose you want to know how many people cheat on their taxes. If you ask them directly, it is likely that some of the cheaters will lie. You can get a more accurate estimate if you ask them indirectly, like this: Ask each person to flip a coin and, without revealing the outcome,\n",
        "\n",
        "If they get heads, they report YES.\n",
        "\n",
        "If they get tails, they honestly answer the question “Do you cheat on your taxes?”\n",
        "\n",
        "If someone says YES, we don’t know whether they actually cheat on their taxes; they might have flipped heads. Knowing this, people might be more willing to answer honestly.\n",
        "\n",
        "Suppose you survey 100 people this way and get 80 YESes and 20 NOs. Based on this data, what is the posterior distribution for the fraction of people who cheat on their taxes? What is the most likely quantity in the posterior distribution?"
      ],
      "metadata": {
        "id": "-0ANfSCcYCj9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwddt3mZ8Kr9"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import beta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install empiricaldist\n",
        "from empiricaldist import Pmf"
      ],
      "metadata": {
        "id": "JkUKrqW08koW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=1;b=1 #beta(1,1)\n",
        "hypos=np.linspace(0,1,101)\n",
        "x=beta.pdf(hypos,a,b)\n",
        "prior=Pmf(x,hypos)"
      ],
      "metadata": {
        "id": "VY2XpAfr8kku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hypos,x) #prior plot"
      ],
      "metadata": {
        "id": "9coGgv1nI3FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "likelihood={'Y':0.5+hypos/2, 'N':(1-hypos)/2} #Q1 WHY?? IS THIS BINOMIAL MODEL?"
      ],
      "metadata": {
        "id": "MdAMUxga8js-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1 : Likelihood 함수가 이와 같이 나오는 이유를 설명해주세요. 그리고 이와 같은 sampling model은 binomial model인가요? 왜 그런가요?"
      ],
      "metadata": {
        "id": "7y0I6HQOQ6wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='Y'*80+'N'*20 #DATA 80 YES, 20 NO\n",
        "posterior1=prior.copy()\n",
        "for data in dataset:\n",
        "    posterior1 *= likelihood[data]\n",
        "posterior1.normalize()"
      ],
      "metadata": {
        "id": "hmRlb_U-8jSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior1.plot(label='80 YES, 20 NO',xlabel='Proportion of cheaters',ylabel='PMF')\n",
        "plt.legend() #Q2 WHY MODE ON 0.6? DATA IS 80 YES & 20 NO. WHY NOT 0.8?"
      ],
      "metadata": {
        "id": "uB5AlwhB9_ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2 : 우리가 구한 Posterior 분포의 꼴이 왜 다음과 같이 나왔을까요? prior의 꼴과 data와 관련하여 설명해주세요. 그리고 data는 YES와 NO의 비율이 4:1인데 왜 posterior의 mode는 0.8이 아니라 0.6인걸까요?"
      ],
      "metadata": {
        "id": "nTNjAPXDRWnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='Y'*800+'N'*200 #DATA 800 YES, 200 NO\n",
        "posterior2=prior.copy()\n",
        "for data in dataset:\n",
        "    posterior2 *= likelihood[data]\n",
        "posterior2.normalize()"
      ],
      "metadata": {
        "id": "nKoQIXgW9_r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior2.plot(label='800 YES, 200 NO',xlabel='Proportion of cheaters',ylabel='PMF')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "QNGUH1aY9_pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior1.plot(label='80 YES, 20 NO')\n",
        "posterior2.plot(label='800 YES, 200 NO',xlabel='Proportion of cheaters',ylabel='PMF')\n",
        "plt.legend() #Q3 DIFFERENCE? WHY?"
      ],
      "metadata": {
        "id": "cjrEMvUl9_mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3: 두 posterior 분포는 왜 이렇게 다른 꼴이 나오게 되었을까요?"
      ],
      "metadata": {
        "id": "NtjcWtcyUT6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4: PRIOR와 DATA를 마음대로 바꿔가며 POSTERIOR 분포가 어떻게 변하는지 실험해보세요."
      ],
      "metadata": {
        "id": "aKrH2t6hUwrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4 PRIOR와 DATA를 마음대로 바꿔가며 POSTERIOR 분포가 어떻게 변하는지 실험해보세요.\n",
        "a=;b= #a,b SET YOUR OWN PRIOR beta(a,b)\n",
        "hypos=np.linspace(0,1,101)\n",
        "x=beta.pdf(hypos,a,b)\n",
        "prior=Pmf(x,hypos)"
      ],
      "metadata": {
        "id": "kYm_9Ulu9_jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hypos,x) # YOUR OWN PRIOR"
      ],
      "metadata": {
        "id": "OJPKv6bM9_gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='Y'* +'N'* #GIVE THE DATA\n",
        "posterior3=prior.copy()\n",
        "for data in dataset:\n",
        "    posterior3 *= likelihood[data]\n",
        "posterior3.normalize()"
      ],
      "metadata": {
        "id": "DsXVov_0JPd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior3.plot(label=' YES,  NO',xlabel='Proportion of cheaters',ylabel='PMF')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "nkwHGSrrJPa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=;b= #a,b SET YOUR OWN PRIOR \n",
        "hypos=np.linspace(0,1,101)\n",
        "x=beta.pdf(hypos,a,b)\n",
        "prior=Pmf(x,hypos)\n",
        "plt.plot(hypos,x) # YOUR OWN PRIOR"
      ],
      "metadata": {
        "id": "8qMt1CwyJPYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='Y'* +'N'* #GIVE THE DATA\n",
        "posterior4=prior.copy()\n",
        "for data in dataset:\n",
        "    posterior4 *= likelihood[data]\n",
        "posterior4.normalize()"
      ],
      "metadata": {
        "id": "89OeUBbFJPVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior4.plot(label=' YES,  NO',xlabel='Proportion of cheaters',ylabel='PMF')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "TthRIt0MJPSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior3.plot(label=' YES,  NO')\n",
        "posterior4.plot(label=' YES,  NO',xlabel='Proportion of cheaters',ylabel='PMF')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "7a11axOWJPPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x9WiwwdtJPJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tpT2ksEOXwn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%%눈치채신 분도 계시겠지만 posterior분포의 밑넓이가 1은 아닙니다. 연속형 확률분포의 prior에 likelihood를 곱한게 아니라 linspace(0,1,101)로 쪼갠 x에 해당하는 pdf(x)값을 prior로 사용했기 때문에 엄밀히 말하면 prior가 분포는 되지 못하죠. 하지만 likelihood와의 곱을 통해 posterior의 꼴을 얻어 여러가지의 prior, data의 경우를 가질 때 posterior의 꼴의 비교를 할 수 있다는 점에 의의를 둬주시면 감사하겠습니다.(이산형으로 표현된 posterior의 꼴이고 normalize가 되었으므로 sum(posterior)는 1이 나오긴 합니당)%%% "
      ],
      "metadata": {
        "id": "PyzhPY9uVCXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(posterior1)"
      ],
      "metadata": {
        "id": "uBNgYxShJPG_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}